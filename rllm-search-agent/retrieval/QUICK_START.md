# å¿«é€Ÿå¯åŠ¨æŒ‡å— - é«˜å¹¶å‘æ£€ç´¢æœåŠ¡

## ğŸš€ 30 ç§’å¿«é€Ÿå¯åŠ¨

```bash
# å• worker é«˜å¹¶å‘æ¨¡å¼ï¼ˆæ¨èï¼‰
bash retrieval/launch_server.sh

# æœåŠ¡åœ°å€: http://0.0.0.0:2727
# API æ–‡æ¡£: http://0.0.0.0:2727/docs
# å¥åº·æ£€æŸ¥: http://0.0.0.0:2727/health
```

**å†…å­˜å ç”¨**: ~85GB  
**å¹¶å‘èƒ½åŠ›**: 100+ å¹¶å‘è¯·æ±‚  
**ååé‡**: 10-50 req/s

## âš ï¸ é‡è¦ï¼šé¿å…å†…å­˜æº¢å‡º

### âŒ ä¸è¦è¿™æ ·åš

```bash
# è¿™ä¼šå¯¼è‡´ OOMï¼
bash retrieval/launch_server.sh /path/to/data 2727 10
# 10 workers Ã— 85GB = 850GB å†…å­˜ï¼
```

### âœ… æ­£ç¡®åšæ³•

```bash
# å• worker å¼‚æ­¥æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
bash retrieval/launch_server.sh

# æˆ–æ˜ç¡®æŒ‡å®š
bash retrieval/launch_server.sh /path/to/data 2727 1
```

## ğŸ“Š æ€§èƒ½æµ‹è¯•

```bash
# å®‰è£…æµ‹è¯•ä¾èµ–
pip install aiohttp

# è¿è¡Œæ€§èƒ½æµ‹è¯•
python retrieval/benchmark_concurrency.py \
    --server http://localhost:2727 \
    --requests 100 \
    --concurrent 50
```

## ğŸ”§ å¸¸ç”¨é…ç½®

### ç”Ÿäº§ç¯å¢ƒ

```bash
python retrieval/server.py \
    --workers 1 \
    --host 0.0.0.0 \
    --port 2727 \
    --log-level info
```

### å¼€å‘ç¯å¢ƒï¼ˆè‡ªåŠ¨é‡è½½ï¼‰

```bash
python retrieval/server.py \
    --workers 1 \
    --host 127.0.0.1 \
    --port 2727 \
    --reload \
    --log-level debug
```

### é«˜å¹¶å‘åœºæ™¯

```bash
# ç¡®ä¿ç³»ç»Ÿé™åˆ¶è¶³å¤Ÿ
ulimit -n 65536

# å¯åŠ¨æœåŠ¡
python retrieval/server.py \
    --workers 1 \
    --host 0.0.0.0 \
    --port 2727
```

## ğŸ¯ API ä½¿ç”¨ç¤ºä¾‹

### Python å®¢æˆ·ç«¯

```python
import requests

# åŒæ­¥è¯·æ±‚
response = requests.post(
    "http://localhost:2727/retrieve",
    json={"query": "What is machine learning?", "top_k": 10}
)
results = response.json()

# å¼‚æ­¥è¯·æ±‚ï¼ˆæ¨èï¼‰
import aiohttp
import asyncio

async def search(query: str):
    async with aiohttp.ClientSession() as session:
        async with session.post(
            "http://localhost:2727/retrieve",
            json={"query": query, "top_k": 10}
        ) as response:
            return await response.json()

# æ‰¹é‡å¹¶å‘è¯·æ±‚
queries = ["query1", "query2", "query3"]
results = await asyncio.gather(*[search(q) for q in queries])
```

### cURL

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:2727/health

# æ£€ç´¢è¯·æ±‚
curl -X POST http://localhost:2727/retrieve \
  -H "Content-Type: application/json" \
  -d '{"query": "What is machine learning?", "top_k": 10}'
```

## ğŸ“ˆ ç›‘æ§

### æ£€æŸ¥æœåŠ¡çŠ¶æ€

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:2727/health | jq

# æŸ¥çœ‹è¿›ç¨‹
ps aux | grep "server.py"

# æŸ¥çœ‹å†…å­˜å ç”¨
ps aux | grep "server.py" | awk '{print $6/1024/1024 " GB"}'
```

### å®æ—¶ç›‘æ§

```bash
# ç›‘æ§å†…å­˜
watch -n 1 'ps aux | grep server.py | grep -v grep'

# ç›‘æ§è¿æ¥æ•°
watch -n 1 'netstat -an | grep :2727 | grep ESTABLISHED | wc -l'
```

## ğŸ› é—®é¢˜æ’æŸ¥

### æœåŠ¡æ— æ³•å¯åŠ¨

```bash
# æ£€æŸ¥ç«¯å£å ç”¨
netstat -tlnp | grep 2727

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
# æ—¥å¿—ä¼šè¾“å‡ºåˆ°ç»ˆç«¯

# æ£€æŸ¥æ•°æ®æ–‡ä»¶
ls -lh /mnt/public/sunjinfeng/data/search_data/prebuilt_indices/
```

### å†…å­˜æº¢å‡º

```bash
# ç¡®è®¤åªæœ‰ 1 ä¸ª worker
ps aux | grep "server.py" | wc -l

# åº”è¯¥åªæœ‰ 2 è¡Œï¼ˆ1 ä¸ªä¸»è¿›ç¨‹ + 1 ä¸ª workerï¼‰

# å¦‚æœæœ‰å¤šä¸ªè¿›ç¨‹ï¼Œæ€æ‰é‡å¯
pkill -f "server.py"
bash retrieval/launch_server.sh
```

### æ€§èƒ½ä¸ä½³

```bash
# è¿è¡Œæ€§èƒ½æµ‹è¯•
python retrieval/benchmark_concurrency.py --concurrent 50

# æ£€æŸ¥ CPU ä½¿ç”¨ç‡
htop

# æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ
ping your_server_ip
```

## ğŸ“š æ›´å¤šä¿¡æ¯

- **å®Œæ•´æ–‡æ¡£**: `HIGH_CONCURRENCY_GUIDE.md`
- **API æ–‡æ¡£**: http://localhost:2727/docs
- **æ€§èƒ½æµ‹è¯•**: `benchmark_concurrency.py`

## ğŸ’¡ å…³é”®è¦ç‚¹

1. âœ… **é»˜è®¤ä½¿ç”¨ 1 worker** - å·²ä¼˜åŒ–å¼‚æ­¥é«˜å¹¶å‘
2. âœ… **å†…å­˜å ç”¨ ~85GB** - ä¸æ˜¯ 850GB
3. âœ… **å¯å¤„ç† 100+ å¹¶å‘** - å• worker è¶³å¤Ÿ
4. âŒ **é¿å…å¤š worker** - é™¤éæœ‰å……è¶³å†…å­˜å’Œæ˜ç¡®éœ€æ±‚
5. âš¡ **ä½¿ç”¨å¼‚æ­¥å®¢æˆ·ç«¯** - è·å¾—æœ€ä½³æ€§èƒ½

## ğŸ“ æŠ€æœ¯åŸç†

```
ä¼ ç»Ÿå¤š worker æ¨¡å¼:
Worker 1: [Model 85GB] [Index 85GB] 
Worker 2: [Model 85GB] [Index 85GB]
...
æ€»è®¡: N Ã— 85GB âŒ

ä¼˜åŒ–åå¼‚æ­¥æ¨¡å¼:
Worker 1: [Model 85GB] [Index 85GB] 
          â†“
    [Async Event Loop]
          â†“
    [Thread Pool for CPU tasks]
          â†“
    å¤„ç† 100+ å¹¶å‘è¯·æ±‚ âœ…
æ€»è®¡: 85GB
```

**å…³é”®**: é€šè¿‡å¼‚æ­¥ I/O å’Œçº¿ç¨‹æ± ï¼Œå• worker å¯ä»¥åœ¨ç­‰å¾… CPU ä»»åŠ¡æ—¶å¤„ç†å…¶ä»–è¯·æ±‚ï¼Œå®ç°é«˜å¹¶å‘ã€‚

